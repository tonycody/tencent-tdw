query: CREATE TABLE dest1(key INT, value STRING) STORED AS TEXTFILE
query: EXPLAIN EXTENDED
FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
INSERT OVERWRITE TABLE dest1 SELECT src1.key, src2.value where src1.ds = '2008-04-08' and src1.hr = '12'
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB srcpart) src1) (TOK_TABREF (TOK_TAB src) src2) (= (. (TOK_TABLE_OR_COL src1) key) (. (TOK_TABLE_OR_COL src2) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TABDEST (TOK_TAB dest1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL src1) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL src2) value))) (TOK_WHERE (and (= (. (TOK_TABLE_OR_COL src1) ds) '2008-04-08') (= (. (TOK_TABLE_OR_COL src1) hr) '12')))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:;depends on:Stage-1;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        default_db/srcpart#src1 
          Operator:          TableScan
            alias: default_db/srcpart#src1
            Operator:            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: ((ds = '2008-04-08') and (hr = '12'))
                  type: boolean
              Operator:              Reduce Output Operator
                key expressions:
                      expr: key
                      type: string
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    properties:
                      columns joinkey0
                      serialization.sort.order +
                      columns.types string
                sort order: +
                output key names: reducesinkkey0
                output value names: _col0, _col2, _col3
                Map-reduce partition columns:
                      expr: key
                      type: string
                tag: 0
                value expressions:
                      expr: key
                      type: string
                      expr: ds
                      type: string
                      expr: hr
                      type: string
        default_db/src#src2 
          Operator:          TableScan
            alias: default_db/src#src2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns joinkey0
                    serialization.sort.order +
                    columns.types string
              sort order: +
              output key names: reducesinkkey0
              output value names: _col1
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
              value expressions:
                    expr: value
                    type: string
      Needs Tagging: true
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart/p0/sp2 [default_db/srcpart#src1]
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src [default_db/src#src2]
      Path -> Partition:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart/p0/sp2 
          Partition
          
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name srcpart
                columns.types string:string:string:string
                serialization.ddl struct srcpart { string key, string value, string ds, string hr}
                serialization.format 1
                columns key,value,ds,hr
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: srcpart
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src 
          Partition
          
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name src
                columns.types string:string
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                columns key,value
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: src
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col2} {VALUE._col3}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col2, _col3, _col5
          Operator:          Filter Operator
            isSamplingPred: false
            predicate:
                expr: ((_col2 = '2008-04-08') and (_col3 = '12'))
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col5
                    type: string
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: UDFToInteger(_col0)
                      type: int
                      expr: _col1
                      type: string
                outputColumnNames: _col0, _col1
                Operator:                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  directory: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2135338073/10000
                  table:
                    table descs
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        name dest1
                        columns.types int:string
                        serialization.ddl struct dest1 { i32 key, string value}
                        serialization.format 1
                        columns key,value
                        bucket_count -1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/dest1
                        db default_db
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: dest1

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2135338073/10000
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name dest1
                columns.types int:string
                serialization.ddl struct dest1 { i32 key, string value}
                serialization.format 1
                columns key,value
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/dest1
                db default_db
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: dest1
          tmp directory: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2135338073/10001

query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
INSERT OVERWRITE TABLE dest1 SELECT src1.key, src2.value where src1.ds = '2008-04-08' and src1.hr = '12'
Output: default_db/dest1
query: SELECT dest1.* FROM dest1
Input: default_db/dest1
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/886766362/10000
query: EXPLAIN EXTENDED
FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
INSERT OVERWRITE TABLE dest1 SELECT src1.key, src2.value where src1.ds = '2008-04-08' and src1.hr = '18'
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TAB srcpart) src1) (TOK_TABREF (TOK_TAB src) src2) (= (. (TOK_TABLE_OR_COL src1) key) (. (TOK_TABLE_OR_COL src2) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_TABDEST (TOK_TAB dest1))) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL src1) key)) (TOK_SELEXPR (. (TOK_TABLE_OR_COL src2) value))) (TOK_WHERE (and (= (. (TOK_TABLE_OR_COL src1) ds) '2008-04-08') (= (. (TOK_TABLE_OR_COL src1) hr) '18')))))

STAGE DEPENDENCIES:
  Stage-1
    type:root stage;
  Stage-0
    type:;depends on:Stage-1;

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        default_db/srcpart#src1 
          Operator:          TableScan
            alias: default_db/srcpart#src1
            Operator:            Filter Operator
              isSamplingPred: false
              predicate:
                  expr: ((ds = '2008-04-08') and (hr = '18'))
                  type: boolean
              Operator:              Reduce Output Operator
                key expressions:
                      expr: key
                      type: string
                key serialize infos:
                  table descs
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    properties:
                      columns joinkey0
                      serialization.sort.order +
                      columns.types string
                sort order: +
                output key names: reducesinkkey0
                output value names: _col0, _col2, _col3
                Map-reduce partition columns:
                      expr: key
                      type: string
                tag: 0
                value expressions:
                      expr: key
                      type: string
                      expr: ds
                      type: string
                      expr: hr
                      type: string
        default_db/src#src2 
          Operator:          TableScan
            alias: default_db/src#src2
            Operator:            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              key serialize infos:
                table descs
                  input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                  properties:
                    columns joinkey0
                    serialization.sort.order +
                    columns.types string
              sort order: +
              output key names: reducesinkkey0
              output value names: _col1
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
              value expressions:
                    expr: value
                    type: string
      Needs Tagging: true
      Path -> Alias:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart/p0/sp2 [default_db/srcpart#src1]
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src [default_db/src#src2]
      Path -> Partition:
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart/p0/sp2 
          Partition
          
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name srcpart
                columns.types string:string:string:string
                serialization.ddl struct srcpart { string key, string value, string ds, string hr}
                serialization.format 1
                columns key,value,ds,hr
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/srcpart
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: srcpart
        file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src 
          Partition
          
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name src
                columns.types string:string
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                columns key,value
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/src
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: src
      Reduce Operator Tree:
        Operator:        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0} {VALUE._col2} {VALUE._col3}
            1 {VALUE._col1}
          handleSkewJoin: false
          outputColumnNames: _col0, _col2, _col3, _col5
          Operator:          Filter Operator
            isSamplingPred: false
            predicate:
                expr: ((_col2 = '2008-04-08') and (_col3 = '18'))
                type: boolean
            Operator:            Select Operator
              expressions:
                    expr: _col0
                    type: string
                    expr: _col5
                    type: string
              outputColumnNames: _col0, _col1
              Operator:              Select Operator
                expressions:
                      expr: UDFToInteger(_col0)
                      type: int
                      expr: _col1
                      type: string
                outputColumnNames: _col0, _col1
                Operator:                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  directory: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2137752228/10000
                  table:
                    table descs
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      properties:
                        name dest1
                        columns.types int:string
                        serialization.ddl struct dest1 { i32 key, string value}
                        serialization.format 1
                        columns key,value
                        bucket_count -1
                        serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                        file.inputformat org.apache.hadoop.mapred.TextInputFormat
                        file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                        location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/dest1
                        db default_db
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                      name: dest1

  Stage: Stage-0
    Move Operator
      tables:
          replace: true
          source: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2137752228/10000
          table:
            table descs
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                name dest1
                columns.types int:string
                serialization.ddl struct dest1 { i32 key, string value}
                serialization.format 1
                columns key,value
                bucket_count -1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                file.inputformat org.apache.hadoop.mapred.TextInputFormat
                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                location file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/test/data/warehouse/default_db/dest1
                db default_db
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: dest1
          tmp directory: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/2137752228/10001

query: FROM srcpart src1 JOIN src src2 ON (src1.key = src2.key)
INSERT OVERWRITE TABLE dest1 SELECT src1.key, src2.value where src1.ds = '2008-04-08' and src1.hr = '18'
Output: default_db/dest1
query: SELECT dest1.* FROM dest1
Input: default_db/dest1
Output: file:/data/tdwadmin/tdwqev1.0R020/qe/build/ql/tmp/1617403293/10000
0	val_0
0	val_0
0	val_0
119	val_119
119	val_119
119	val_119
129	val_129
129	val_129
158	val_158
172	val_172
172	val_172
179	val_179
179	val_179
208	val_208
208	val_208
208	val_208
230	val_230
230	val_230
230	val_230
230	val_230
230	val_230
24	val_24
24	val_24
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
348	val_348
411	val_411
42	val_42
42	val_42
431	val_431
431	val_431
431	val_431
463	val_463
463	val_463
466	val_466
466	val_466
466	val_466
496	val_496
58	val_58
58	val_58
8	val_8
84	val_84
84	val_84
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
query: SELECT dest1.* FROM dest1
